{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "import tensorflow as tf\n",
    "if not tf.test.is_gpu_available():\n",
    "    print('GPU is not available. Runtime -> Change runtime type to enable GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(dtype, visualize=False):\n",
    "    if dtype == 'mnist_dnn':\n",
    "        import tensorflow as tf\n",
    "        (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "        \n",
    "        X_train = X_train.reshape((60000, 28*28)) / 255.0\n",
    "        X_test = X_test.reshape((10000, 28*28)) / 255.0\n",
    "        if visualize:\n",
    "            id = 0\n",
    "            plt.figure()\n",
    "            plt.imshow(X_train[id].reshape(28, 28))\n",
    "            plt.title('class {}'.format(y_train[id]))\n",
    "    elif dtype == 'mnist_cnn':\n",
    "        import tensorflow as tf\n",
    "        (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "        \n",
    "        X_train = X_train.reshape((60000, 28, 28, 1)) / 255.0\n",
    "        X_test = X_test.reshape((10000, 28, 28, 1)) / 255.0\n",
    "        if visualize:\n",
    "            id = 0\n",
    "            plt.figure()\n",
    "            plt.imshow(X_train[id].reshape(28, 28))\n",
    "            plt.title('class {}'.format(y_train[id]))\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = build_dataset('mnist_cnn', visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(mtype, cdim=64, ddim=64):\n",
    "    if mtype == 'dnn':\n",
    "        from tensorflow.keras import layers, models\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(units=128, activation='relu', input_shape=(28*28,)))\n",
    "        model.add(layers.Dense(units=10, activation='softmax'))\n",
    "        model.summary()\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        clf = model\n",
    "\n",
    "    elif mtype == 'cnn':\n",
    "        from tensorflow.keras import layers, models\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(cdim, (3, 3), activation='relu'))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(ddim, activation='relu'))\n",
    "        model.add(layers.Dense(10, activation='softmax'))\n",
    "        model.summary()\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        clf = model\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_tf(config={}):\n",
    "    X_train, y_train, X_test, y_test = build_dataset(config['dataset'])\n",
    "    clf = build_model(config['model'])\n",
    "    \n",
    "    clf.fit(X_train, y_train, epochs=5)\n",
    "    test_loss, test_acc = clf.evaluate(X_test, y_test, verbose=2)\n",
    "    \n",
    "    print('test accuracy: {}, loss: {}'.format(test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.2601 - accuracy: 0.9266\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.1137 - accuracy: 0.9669\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0790 - accuracy: 0.9764\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0585 - accuracy: 0.9819\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0444 - accuracy: 0.9862\n",
      "10000/1 - 0s - loss: 0.0443 - accuracy: 0.9737\n",
      "test accuracy: 0.9736999869346619, loss: 0.086170801733993\n",
      "CPU times: user 32.2 s, sys: 5.53 s, total: 37.7 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_tf({'dataset': 'mnist_dnn', 'model': 'dnn'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 65,642\n",
      "Trainable params: 65,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 11s 184us/sample - loss: 0.1654 - accuracy: 0.9485\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 11s 175us/sample - loss: 0.0504 - accuracy: 0.9844\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 11s 175us/sample - loss: 0.0357 - accuracy: 0.9890\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 10s 175us/sample - loss: 0.0276 - accuracy: 0.9914\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 11s 175us/sample - loss: 0.0207 - accuracy: 0.9936\n",
      "10000/1 - 1s - loss: 0.0158 - accuracy: 0.9898\n",
      "test accuracy: 0.989799976348877, loss: 0.03139295010878414\n",
      "CPU times: user 4min 37s, sys: 9.05 s, total: 4min 46s\n",
      "Wall time: 54.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_tf({'dataset': 'mnist_cnn', 'model': 'cnn'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up colab environment\")\n",
    "!pip uninstall -y -q pyarrow\n",
    "!pip install -q -U ray[tune]\n",
    "!pip install -q ray[debug]\n",
    "\n",
    "# A hack to force the runtime to restart, needed to include the above dependencies.\n",
    "print(\"Done installing! Restarting via forced crash (this is not an issue).\")\n",
    "import os\n",
    "os._exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "class TuneReporterCallback(keras.callbacks.Callback):\n",
    "    \"\"\"Tune Callback for Keras.\n",
    "    \n",
    "    The callback is invoked every epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, logs={}):\n",
    "        self.iteration = 0\n",
    "        super(TuneReporterCallback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.iteration += 1\n",
    "        tune.report(keras_info=logs, mean_accuracy=logs.get(\"accuracy\"), mean_loss=logs.get(\"loss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tf(config={}):\n",
    "    X_train, y_train, X_test, y_test = build_dataset(config['dataset'])\n",
    "    clf = build_model(config['model'], config['cdim'], config['ddim'])\n",
    "    \n",
    "    callbacks = [TuneReporterCallback()]\n",
    "    clf.fit(X_train, y_train, epochs=5, callbacks=callbacks)\n",
    "    test_loss, test_acc = clf.evaluate(X_test, y_test, verbose=2)\n",
    "    tune.report(mean_accuracy = test_acc)\n",
    "    \n",
    "    print('test accuracy: {}, loss: {}'.format(test_acc, test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_space = {\n",
    "    'model': 'cnn',\n",
    "    'dataset': 'mnist_cnn',\n",
    "    'cdim': tune.grid_search([64, 128, 256]),\n",
    "    'ddim': tune.grid_search([64, 128, 256]),\n",
    "}\n",
    "ray.shutdown()\n",
    "ray.init(log_to_driver=False)\n",
    "! rm -rf ~/ray_results/train_tf\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_tf, \n",
    "    verbose=1, \n",
    "    resources_per_trial={'gpu': 1},\n",
    "    config=hyperparameter_space)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
